{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7604cb-c3ec-417f-9a95-d7a384b6c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation MSE: 0.14\n",
      "Mean Squared Error (MSE): 0.13\n",
      "R2 Score: 0.98\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Fetch Data\n",
    "def fetch_data(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()  # Raise an error for bad HTTP responses\n",
    "        data = response.json()\n",
    "        return pd.DataFrame(data)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame for safety\n",
    "\n",
    "# Define features and target\n",
    "features = [\n",
    "    \"goalsScored\", \"assists\", \"cleanSheets\", \"penaltiesSaved\", \"penaltiesMissed\",\n",
    "    \"ownGoals\", \"yellowCards\", \"redCards\", \"saves\", \"bonus\", \"bonusPointsSystem\",\n",
    "    \"dreamTeamCount\", \"expectedGoals\", \"expectedAssists\", \"expectedGoalInvolvements\",\n",
    "    \"expectedGoalsConceded\", \"expectedGoalsPer90\", \"expectedAssistsPer90\",\n",
    "    \"goalsConcededPer90\", \"startsPer90\", \"cleanSheetsPer90\"\n",
    "]\n",
    "target = \"totalPoints\"\n",
    "\n",
    "# Fetch and preprocess data\n",
    "url = 'http://localhost:5235/api/player/playersdata/train'\n",
    "data = fetch_data(url)\n",
    "\n",
    "\n",
    "# Combine firstName and secondName into a single playerName column\n",
    "data[\"playerName\"] = data[\"firstName\"] + \" \" + data[\"secondName\"]\n",
    "\n",
    "# Sort data by playerName and gameweek\n",
    "data = data.sort_values(by=[\"playerName\", \"gameWeek\"])\n",
    "\n",
    "# Create previousPoints and rolling features\n",
    "data[\"previousPoints\"] = data.groupby(\"playerName\")[\"totalPoints\"].shift(1)\n",
    "data[\"avgPointsLast3\"] = data.groupby(\"playerName\")[\"totalPoints\"].rolling(3).mean().reset_index(0, drop=True)\n",
    "data[\"maxPointsLast5\"] = data.groupby(\"playerName\")[\"totalPoints\"].rolling(5).max().reset_index(0, drop=True)\n",
    "\n",
    "# Drop rows with NaN in previousPoints or rolling features\n",
    "data = data.dropna(subset=[\"previousPoints\", \"avgPointsLast3\", \"maxPointsLast5\"])\n",
    "\n",
    "# Prepare features and target\n",
    "X = data[features + [\"avgPointsLast3\", \"maxPointsLast5\"]]\n",
    "y = data[target]\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter Tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.7, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "# XGBoost Model\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\")\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Retrieve Best Parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Recreate the model with best parameters\n",
    "best_model = xgb.XGBRegressor(\n",
    "    objective=\"reg:squarederror\",\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "best_model.save_model(\"fantasy_edge_model.json\")\n",
    "\n",
    "# Cross-Validation\n",
    "cv_scores = cross_val_score(best_model, X_scaled, y, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"Cross-Validation MSE: {-cv_scores.mean():.2f}\")\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.2f}\")\n",
    "\n",
    "data.to_csv('Player_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a38a8e0-fbc6-4b79-a4a2-3d81a7087af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_player(player_name):\n",
    "    # Filter player data by name\n",
    "    player_data = data[data[\"playerName\"] == player_name]\n",
    "    if player_data.empty:\n",
    "        return f\"Player '{player_name}' not found in the dataset.\"\n",
    "\n",
    "    # Prepare player features\n",
    "    player_features = player_data[features + [\"avgPointsLast3\", \"maxPointsLast5\"]].iloc[-1:]  # Latest gameweek features\n",
    "    player_features_scaled = scaler.transform(player_features)\n",
    "    \n",
    "    # Predict next gameweek points\n",
    "    predicted_points = best_model.predict(player_features_scaled)[0]\n",
    "    \n",
    "    # Get previous points for the player (last gameweek)\n",
    "    previous_points = player_data[\"previousPoints\"].iloc[-1]\n",
    "    \n",
    "    # Calculate percentage change and trend\n",
    "    if previous_points != 0:\n",
    "        percentage_change = ((predicted_points - previous_points) / previous_points) * 100\n",
    "    else:\n",
    "        percentage_change = 0  # or another default value like 'N/A'\n",
    "    \n",
    "    trend = \"Increasing\" if percentage_change > 0 else \"Decreasing\"\n",
    "\n",
    "    # Check if the player is a goalkeeper (position 1)\n",
    "    position = player_data[\"position\"].values[0]\n",
    "    \n",
    "    # Check if the position is 1 (goalkeeper)\n",
    "    is_goalkeeper = position == 1\n",
    "\n",
    "    # Calculate percentages for non-goalkeepers\n",
    "    if not is_goalkeeper:\n",
    "        # Correct formula for assists_percentage\n",
    "        assists_percentage = player_data[\"assists\"].iloc[-1] / player_data[\"totalPoints\"].iloc[-1] * 100 if player_data[\"totalPoints\"].iloc[-1] > 0 else 0\n",
    "        goals_percentage = player_data[\"goalsScored\"].iloc[-1] / player_data[\"totalPoints\"].iloc[-1] * 100 if player_data[\"totalPoints\"].iloc[-1] > 0 else 0\n",
    "    else:\n",
    "        # For goalkeepers, calculate clean sheet percentage\n",
    "        clean_sheet_percentage = player_data[\"cleanSheets\"].iloc[-1] / player_data[\"totalPoints\"].iloc[-1] * 100 if player_data[\"totalPoints\"].iloc[-1] > 0 else 0\n",
    "\n",
    "    result = {\n",
    "        \"playerName\": player_name,\n",
    "        \"predictedPoints\": round(predicted_points, 2),\n",
    "        \"percentageChange\": f\"{round(percentage_change, 2)}%\",\n",
    "        \"trend\": trend\n",
    "    }\n",
    "\n",
    "    # Add statistics based on whether the player is a goalkeeper or not\n",
    "    if not is_goalkeeper:\n",
    "        result[\"assistsPercentage\"] = f\"{round(assists_percentage, 2)}%\"\n",
    "        result[\"goalsPercentage\"] = f\"{round(goals_percentage, 2)}%\"\n",
    "    else:\n",
    "        result[\"cleanSheetPercentage\"] = f\"{round(clean_sheet_percentage, 2)}%\"\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72ccbe71-0f30-4424-840e-0ba0cd0e01b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(best_model, 'fantasy_edge_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89ae17-a4f8-4afa-a4f7-92aa0363a4c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
